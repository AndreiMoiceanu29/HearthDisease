{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n0     1   39        4.0              0         0.0     0.0                0   \n1     0   46        2.0              0         0.0     0.0                0   \n2     1   48        1.0              1        20.0     0.0                0   \n3     0   61        3.0              1        30.0     0.0                0   \n4     0   46        3.0              1        23.0     0.0                0   \n\n   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n\n   TenYearCHD  \n0           0  \n1           0  \n2           0  \n3           1  \n4           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>male</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>46</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>48</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0</td>\n      <td>61</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0</td>\n      <td>46</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import optimizers\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(units=64,activation='relu', input_dim= 15))\nmodel.add(Dense(units=64, activation='relu', input_dim=100))\nmodel.add(Dense(units=1, activation='sigmoid'))\nsgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy',optimizer='sgd', metrics=['accuracy'])","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"TenYearCHD\"]\ny","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0       0\n1       0\n2       0\n3       1\n4       0\n       ..\n4233    1\n4234    0\n4235    0\n4236    0\n4237    0\nName: TenYearCHD, Length: 4238, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = df[df.columns[:-1]]\n\nX","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n0        1   39        4.0              0         0.0     0.0   \n1        0   46        2.0              0         0.0     0.0   \n2        1   48        1.0              1        20.0     0.0   \n3        0   61        3.0              1        30.0     0.0   \n4        0   46        3.0              1        23.0     0.0   \n...    ...  ...        ...            ...         ...     ...   \n4233     1   50        1.0              1         1.0     0.0   \n4234     1   51        3.0              1        43.0     0.0   \n4235     0   48        2.0              1        20.0     NaN   \n4236     0   44        1.0              1        15.0     0.0   \n4237     0   52        2.0              0         0.0     0.0   \n\n      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n0                   0             0         0    195.0  106.0   70.0  26.97   \n1                   0             0         0    250.0  121.0   81.0  28.73   \n2                   0             0         0    245.0  127.5   80.0  25.34   \n3                   0             1         0    225.0  150.0   95.0  28.58   \n4                   0             0         0    285.0  130.0   84.0  23.10   \n...               ...           ...       ...      ...    ...    ...    ...   \n4233                0             1         0    313.0  179.0   92.0  25.97   \n4234                0             0         0    207.0  126.5   80.0  19.71   \n4235                0             0         0    248.0  131.0   72.0  22.00   \n4236                0             0         0    210.0  126.5   87.0  19.16   \n4237                0             0         0    269.0  133.5   83.0  21.47   \n\n      heartRate  glucose  \n0          80.0     77.0  \n1          95.0     76.0  \n2          75.0     70.0  \n3          65.0    103.0  \n4          85.0     85.0  \n...         ...      ...  \n4233       66.0     86.0  \n4234       65.0     68.0  \n4235       84.0     86.0  \n4236       86.0      NaN  \n4237       80.0    107.0  \n\n[4238 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>male</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>195.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>26.97</td>\n      <td>80.0</td>\n      <td>77.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>46</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>250.0</td>\n      <td>121.0</td>\n      <td>81.0</td>\n      <td>28.73</td>\n      <td>95.0</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>48</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>245.0</td>\n      <td>127.5</td>\n      <td>80.0</td>\n      <td>25.34</td>\n      <td>75.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0</td>\n      <td>61</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>225.0</td>\n      <td>150.0</td>\n      <td>95.0</td>\n      <td>28.58</td>\n      <td>65.0</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0</td>\n      <td>46</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>285.0</td>\n      <td>130.0</td>\n      <td>84.0</td>\n      <td>23.10</td>\n      <td>85.0</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>4233</td>\n      <td>1</td>\n      <td>50</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>313.0</td>\n      <td>179.0</td>\n      <td>92.0</td>\n      <td>25.97</td>\n      <td>66.0</td>\n      <td>86.0</td>\n    </tr>\n    <tr>\n      <td>4234</td>\n      <td>1</td>\n      <td>51</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>43.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>207.0</td>\n      <td>126.5</td>\n      <td>80.0</td>\n      <td>19.71</td>\n      <td>65.0</td>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <td>4235</td>\n      <td>0</td>\n      <td>48</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248.0</td>\n      <td>131.0</td>\n      <td>72.0</td>\n      <td>22.00</td>\n      <td>84.0</td>\n      <td>86.0</td>\n    </tr>\n    <tr>\n      <td>4236</td>\n      <td>0</td>\n      <td>44</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>210.0</td>\n      <td>126.5</td>\n      <td>87.0</td>\n      <td>19.16</td>\n      <td>86.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>4237</td>\n      <td>0</td>\n      <td>52</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>269.0</td>\n      <td>133.5</td>\n      <td>83.0</td>\n      <td>21.47</td>\n      <td>80.0</td>\n      <td>107.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4238 rows Ã— 15 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values='NaN', strategy='mean', axis=0)","execution_count":8,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n  warnings.warn(msg, category=DeprecationWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_values = imputer.fit_transform(X)\ntransformed_values","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array([[  1.        ,  39.        ,   4.        , ...,  26.97      ,\n         80.        ,  77.        ],\n       [  0.        ,  46.        ,   2.        , ...,  28.73      ,\n         95.        ,  76.        ],\n       [  1.        ,  48.        ,   1.        , ...,  25.34      ,\n         75.        ,  70.        ],\n       ...,\n       [  0.        ,  48.        ,   2.        , ...,  22.        ,\n         84.        ,  86.        ],\n       [  0.        ,  44.        ,   1.        , ...,  19.16      ,\n         86.        ,  81.96675325],\n       [  0.        ,  52.        ,   2.        , ...,  21.47      ,\n         80.        , 107.        ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in range(15):\n    min_x = min(transformed_values[:,j])\n    max_x = max(transformed_values[:,j])\n    for i in range(len(transformed_values[:,j])):\n        \n        transformed_values[:,j][i] = (transformed_values[:,j][i] - min_x) / (max_x - min_x)\ntransformed_values","execution_count":64,"outputs":[{"output_type":"execute_result","execution_count":64,"data":{"text/plain":"array([[1.        , 0.        , 1.        , ..., 0.27702375, 0.36363636,\n        0.10451977],\n       [0.        , 0.62816008, 0.18518519, ..., 0.31968008, 0.51515152,\n        0.10169492],\n       [1.        , 0.65712171, 0.        , ..., 0.23751818, 0.31313131,\n        0.08474576],\n       ...,\n       [0.        , 0.92163004, 1.        , ..., 0.1565681 , 0.4040404 ,\n        0.1299435 ],\n       [0.        , 0.84326008, 0.32777778, ..., 0.08773631, 0.42424242,\n        0.11855015],\n       [0.        , 1.        , 1.        , ..., 0.14372273, 0.36363636,\n        0.18926554]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,x_test,y_train,y_test = train_test_split(transformed_values,y, test_size = 0.25, random_state = 42, shuffle = True)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train, epochs = 300)","execution_count":82,"outputs":[{"output_type":"stream","text":"Epoch 1/300\n3178/3178 [==============================] - 0s 97us/step - loss: 0.5569 - accuracy: 0.8427\nEpoch 2/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4661 - accuracy: 0.8452\nEpoch 3/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4499 - accuracy: 0.8452\nEpoch 4/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4450 - accuracy: 0.8452\nEpoch 5/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4418 - accuracy: 0.8452\nEpoch 6/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4391 - accuracy: 0.8452\nEpoch 7/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4368 - accuracy: 0.8452\nEpoch 8/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4344 - accuracy: 0.8452\nEpoch 9/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4324 - accuracy: 0.8452\nEpoch 10/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4306 - accuracy: 0.8452\nEpoch 11/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4289 - accuracy: 0.8452\nEpoch 12/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4273 - accuracy: 0.8452\nEpoch 13/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4259 - accuracy: 0.8452\nEpoch 14/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4245 - accuracy: 0.8452\nEpoch 15/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4232 - accuracy: 0.8452\nEpoch 16/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4221 - accuracy: 0.8452\nEpoch 17/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4209 - accuracy: 0.8452\nEpoch 18/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4199 - accuracy: 0.8452\nEpoch 19/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4190 - accuracy: 0.8452\nEpoch 20/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4182 - accuracy: 0.8452\nEpoch 21/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.4176 - accuracy: 0.8452\nEpoch 22/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4168 - accuracy: 0.8452\nEpoch 23/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4162 - accuracy: 0.8452\nEpoch 24/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4156 - accuracy: 0.8452\nEpoch 25/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4150 - accuracy: 0.8452\nEpoch 26/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4145 - accuracy: 0.8452\nEpoch 27/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4141 - accuracy: 0.8452\nEpoch 28/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4136 - accuracy: 0.8452\nEpoch 29/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4132 - accuracy: 0.8452\nEpoch 30/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4128 - accuracy: 0.8452\nEpoch 31/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4124 - accuracy: 0.8452\nEpoch 32/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4121 - accuracy: 0.8452\nEpoch 33/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4117 - accuracy: 0.8452\nEpoch 34/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4113 - accuracy: 0.8452\nEpoch 35/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4111 - accuracy: 0.8452\nEpoch 36/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4107 - accuracy: 0.8452\nEpoch 37/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4104 - accuracy: 0.8452\nEpoch 38/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4101 - accuracy: 0.8452\nEpoch 39/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4098 - accuracy: 0.8452\nEpoch 40/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4095 - accuracy: 0.8452\nEpoch 41/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4092 - accuracy: 0.8452\nEpoch 42/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4088 - accuracy: 0.8452\nEpoch 43/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4087 - accuracy: 0.8452\nEpoch 44/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4084 - accuracy: 0.8452\nEpoch 45/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4080 - accuracy: 0.8452\nEpoch 46/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4078 - accuracy: 0.8452\nEpoch 47/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4076 - accuracy: 0.8452\nEpoch 48/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4072 - accuracy: 0.8452\nEpoch 49/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4069 - accuracy: 0.8452\nEpoch 50/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4068 - accuracy: 0.8452\nEpoch 51/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4065 - accuracy: 0.8452\nEpoch 52/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4062 - accuracy: 0.8452\nEpoch 53/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4059 - accuracy: 0.8452\nEpoch 54/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4058 - accuracy: 0.8452\nEpoch 55/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4054 - accuracy: 0.8452\nEpoch 56/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.4051 - accuracy: 0.8452\nEpoch 57/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4048 - accuracy: 0.8452\nEpoch 58/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4045 - accuracy: 0.8452\nEpoch 59/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4043 - accuracy: 0.8452\nEpoch 60/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4040 - accuracy: 0.8452\nEpoch 61/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4038 - accuracy: 0.8452\nEpoch 62/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4035 - accuracy: 0.8452\nEpoch 63/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4032 - accuracy: 0.8452\nEpoch 64/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4031 - accuracy: 0.8452\nEpoch 65/300\n3178/3178 [==============================] - 0s 58us/step - loss: 0.4027 - accuracy: 0.8452\nEpoch 66/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4025 - accuracy: 0.8452\nEpoch 67/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4022 - accuracy: 0.8452\nEpoch 68/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4018 - accuracy: 0.8452\nEpoch 69/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.4016 - accuracy: 0.8452\nEpoch 70/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4013 - accuracy: 0.8452\nEpoch 71/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.4010 - accuracy: 0.8452\nEpoch 72/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.4006 - accuracy: 0.8452\nEpoch 73/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.4006 - accuracy: 0.8452\nEpoch 74/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.4004 - accuracy: 0.8455\nEpoch 75/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3999 - accuracy: 0.8455\nEpoch 76/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3998 - accuracy: 0.8461\nEpoch 77/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3995 - accuracy: 0.8461\nEpoch 78/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3992 - accuracy: 0.8461\nEpoch 79/300\n","name":"stdout"},{"output_type":"stream","text":"3178/3178 [==============================] - 0s 53us/step - loss: 0.3990 - accuracy: 0.8464\nEpoch 80/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3986 - accuracy: 0.8464\nEpoch 81/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3985 - accuracy: 0.8468\nEpoch 82/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3982 - accuracy: 0.8468\nEpoch 83/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3979 - accuracy: 0.8468\nEpoch 84/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3977 - accuracy: 0.8468\nEpoch 85/300\n3178/3178 [==============================] - 0s 57us/step - loss: 0.3975 - accuracy: 0.8468\nEpoch 86/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3969 - accuracy: 0.8468\nEpoch 87/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3968 - accuracy: 0.8468\nEpoch 88/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3966 - accuracy: 0.8468\nEpoch 89/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3964 - accuracy: 0.8468\nEpoch 90/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3959 - accuracy: 0.8468\nEpoch 91/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3959 - accuracy: 0.8468\nEpoch 92/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3957 - accuracy: 0.8471\nEpoch 93/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3955 - accuracy: 0.8471\nEpoch 94/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3951 - accuracy: 0.8471\nEpoch 95/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3949 - accuracy: 0.8468\nEpoch 96/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3947 - accuracy: 0.8468\nEpoch 97/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.3943 - accuracy: 0.8471\nEpoch 98/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3939 - accuracy: 0.8471\nEpoch 99/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3938 - accuracy: 0.8477\nEpoch 100/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3935 - accuracy: 0.8464\nEpoch 101/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3928 - accuracy: 0.8474\nEpoch 102/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3931 - accuracy: 0.8468\nEpoch 103/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3926 - accuracy: 0.8471\nEpoch 104/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3927 - accuracy: 0.8471\nEpoch 105/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3923 - accuracy: 0.8474\nEpoch 106/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3920 - accuracy: 0.8471\nEpoch 107/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3917 - accuracy: 0.8471\nEpoch 108/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3917 - accuracy: 0.8477\nEpoch 109/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3916 - accuracy: 0.8468\nEpoch 110/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3912 - accuracy: 0.8464\nEpoch 111/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3908 - accuracy: 0.8474\nEpoch 112/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3908 - accuracy: 0.8468\nEpoch 113/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3904 - accuracy: 0.8464\nEpoch 114/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3903 - accuracy: 0.8471\nEpoch 115/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3897 - accuracy: 0.8480\nEpoch 116/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3899 - accuracy: 0.8468\nEpoch 117/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3897 - accuracy: 0.8471\nEpoch 118/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3891 - accuracy: 0.8468\nEpoch 119/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3890 - accuracy: 0.8477\nEpoch 120/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3887 - accuracy: 0.8471\nEpoch 121/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3887 - accuracy: 0.8474\nEpoch 122/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3886 - accuracy: 0.8468\nEpoch 123/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3884 - accuracy: 0.8471\nEpoch 124/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3881 - accuracy: 0.8474\nEpoch 125/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3878 - accuracy: 0.8464\nEpoch 126/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3879 - accuracy: 0.8468\nEpoch 127/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3873 - accuracy: 0.8464\nEpoch 128/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3873 - accuracy: 0.8477\nEpoch 129/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3875 - accuracy: 0.8477\nEpoch 130/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3870 - accuracy: 0.8477\nEpoch 131/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3870 - accuracy: 0.8471\nEpoch 132/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.3864 - accuracy: 0.8493\nEpoch 133/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3866 - accuracy: 0.8474\nEpoch 134/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3863 - accuracy: 0.8480\nEpoch 135/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3855 - accuracy: 0.8486\nEpoch 136/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3862 - accuracy: 0.8480\nEpoch 137/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3862 - accuracy: 0.8477\nEpoch 138/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3860 - accuracy: 0.8480\nEpoch 139/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3856 - accuracy: 0.8490\nEpoch 140/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3857 - accuracy: 0.8483\nEpoch 141/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3855 - accuracy: 0.8480\nEpoch 142/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3851 - accuracy: 0.8480\nEpoch 143/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3852 - accuracy: 0.8496\nEpoch 144/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3846 - accuracy: 0.8486\nEpoch 145/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3846 - accuracy: 0.8496\nEpoch 146/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3849 - accuracy: 0.8493\nEpoch 147/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3848 - accuracy: 0.8493\nEpoch 148/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3847 - accuracy: 0.8496\nEpoch 149/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3843 - accuracy: 0.8496\nEpoch 150/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3843 - accuracy: 0.8502\nEpoch 151/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3841 - accuracy: 0.8499\nEpoch 152/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3839 - accuracy: 0.8490\nEpoch 153/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3841 - accuracy: 0.8496\nEpoch 154/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3834 - accuracy: 0.8518\nEpoch 155/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3841 - accuracy: 0.8508\nEpoch 156/300\n","name":"stdout"},{"output_type":"stream","text":"3178/3178 [==============================] - 0s 53us/step - loss: 0.3837 - accuracy: 0.8515\nEpoch 157/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3835 - accuracy: 0.8502\nEpoch 158/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3834 - accuracy: 0.8502\nEpoch 159/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3826 - accuracy: 0.8499\nEpoch 160/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3832 - accuracy: 0.8508\nEpoch 161/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3831 - accuracy: 0.8518\nEpoch 162/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3829 - accuracy: 0.8505\nEpoch 163/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3831 - accuracy: 0.8508\nEpoch 164/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3829 - accuracy: 0.8505\nEpoch 165/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3828 - accuracy: 0.8515\nEpoch 166/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3828 - accuracy: 0.8512\nEpoch 167/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3825 - accuracy: 0.8515\nEpoch 168/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3827 - accuracy: 0.8515\nEpoch 169/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3820 - accuracy: 0.8518\nEpoch 170/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3825 - accuracy: 0.8512\nEpoch 171/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3817 - accuracy: 0.8499\nEpoch 172/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3822 - accuracy: 0.8515\nEpoch 173/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3822 - accuracy: 0.8508\nEpoch 174/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3820 - accuracy: 0.8512\nEpoch 175/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3818 - accuracy: 0.8496\nEpoch 176/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3818 - accuracy: 0.8505\nEpoch 177/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3819 - accuracy: 0.8518\nEpoch 178/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3820 - accuracy: 0.8512\nEpoch 179/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3817 - accuracy: 0.8518\nEpoch 180/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3816 - accuracy: 0.8524\nEpoch 181/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3815 - accuracy: 0.8518\nEpoch 182/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3819 - accuracy: 0.8508\nEpoch 183/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3817 - accuracy: 0.8508\nEpoch 184/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3816 - accuracy: 0.8518\nEpoch 185/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3816 - accuracy: 0.8502\nEpoch 186/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3812 - accuracy: 0.8515\nEpoch 187/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3812 - accuracy: 0.8512\nEpoch 188/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3810 - accuracy: 0.8521\nEpoch 189/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3811 - accuracy: 0.8512\nEpoch 190/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3811 - accuracy: 0.8512\nEpoch 191/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3807 - accuracy: 0.8531\nEpoch 192/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3813 - accuracy: 0.8524\nEpoch 193/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3809 - accuracy: 0.8515\nEpoch 194/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3810 - accuracy: 0.8527\nEpoch 195/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3810 - accuracy: 0.8527\nEpoch 196/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3808 - accuracy: 0.8518\nEpoch 197/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3807 - accuracy: 0.8521\nEpoch 198/300\n3178/3178 [==============================] - 0s 56us/step - loss: 0.3806 - accuracy: 0.8515\nEpoch 199/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3804 - accuracy: 0.8527\nEpoch 200/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3804 - accuracy: 0.8512\nEpoch 201/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3806 - accuracy: 0.8515\nEpoch 202/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3803 - accuracy: 0.8534\nEpoch 203/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3805 - accuracy: 0.8527\nEpoch 204/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3803 - accuracy: 0.8524\nEpoch 205/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3805 - accuracy: 0.8531\nEpoch 206/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3806 - accuracy: 0.8515\nEpoch 207/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3806 - accuracy: 0.8521\nEpoch 208/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3802 - accuracy: 0.8508\nEpoch 209/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3804 - accuracy: 0.8527\nEpoch 210/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3795 - accuracy: 0.8512\nEpoch 211/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3805 - accuracy: 0.8524\nEpoch 212/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3799 - accuracy: 0.8512\nEpoch 213/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3801 - accuracy: 0.8531\nEpoch 214/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3797 - accuracy: 0.8515\nEpoch 215/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3796 - accuracy: 0.8524\nEpoch 216/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3800 - accuracy: 0.8531\nEpoch 217/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3796 - accuracy: 0.8521\nEpoch 218/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3799 - accuracy: 0.8524\nEpoch 219/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3797 - accuracy: 0.8524\nEpoch 220/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3799 - accuracy: 0.8524\nEpoch 221/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3797 - accuracy: 0.8537\nEpoch 222/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3795 - accuracy: 0.8534\nEpoch 223/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3800 - accuracy: 0.8524\nEpoch 224/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3796 - accuracy: 0.8531\nEpoch 225/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3796 - accuracy: 0.8540\nEpoch 226/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3795 - accuracy: 0.8521\nEpoch 227/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3796 - accuracy: 0.8531\nEpoch 228/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3796 - accuracy: 0.8537\nEpoch 229/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3794 - accuracy: 0.8518\nEpoch 230/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3796 - accuracy: 0.8521\nEpoch 231/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3789 - accuracy: 0.8518\nEpoch 232/300\n3178/3178 [==============================] - 0s 50us/step - loss: 0.3791 - accuracy: 0.8515\nEpoch 233/300\n","name":"stdout"},{"output_type":"stream","text":"3178/3178 [==============================] - 0s 52us/step - loss: 0.3797 - accuracy: 0.8527\nEpoch 234/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3792 - accuracy: 0.8531\nEpoch 235/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3792 - accuracy: 0.8515\nEpoch 236/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3795 - accuracy: 0.8524\nEpoch 237/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3792 - accuracy: 0.8537\nEpoch 238/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3790 - accuracy: 0.8527\nEpoch 239/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3778 - accuracy: 0.8537\nEpoch 240/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3791 - accuracy: 0.8531\nEpoch 241/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3792 - accuracy: 0.8540\nEpoch 242/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3790 - accuracy: 0.8521\nEpoch 243/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3784 - accuracy: 0.8524\nEpoch 244/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3795 - accuracy: 0.8531\nEpoch 245/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3784 - accuracy: 0.8518\nEpoch 246/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3790 - accuracy: 0.8531\nEpoch 247/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3786 - accuracy: 0.8527\nEpoch 248/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3783 - accuracy: 0.8524\nEpoch 249/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3786 - accuracy: 0.8524\nEpoch 250/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3787 - accuracy: 0.8531\nEpoch 251/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3788 - accuracy: 0.8527\nEpoch 252/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3785 - accuracy: 0.8518\nEpoch 253/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3786 - accuracy: 0.8527\nEpoch 254/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3785 - accuracy: 0.8524\nEpoch 255/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3788 - accuracy: 0.8531\nEpoch 256/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3782 - accuracy: 0.8534\nEpoch 257/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3784 - accuracy: 0.8527\nEpoch 258/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3787 - accuracy: 0.8521\nEpoch 259/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3787 - accuracy: 0.8537\nEpoch 260/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3787 - accuracy: 0.8531\nEpoch 261/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3786 - accuracy: 0.8521\nEpoch 262/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3785 - accuracy: 0.8527\nEpoch 263/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3786 - accuracy: 0.8531\nEpoch 264/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3783 - accuracy: 0.8534\nEpoch 265/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3780 - accuracy: 0.8540\nEpoch 266/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3783 - accuracy: 0.8537\nEpoch 267/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3779 - accuracy: 0.8534\nEpoch 268/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3780 - accuracy: 0.8518\nEpoch 269/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3779 - accuracy: 0.8527\nEpoch 270/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3779 - accuracy: 0.8537\nEpoch 271/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3776 - accuracy: 0.8521\nEpoch 272/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3777 - accuracy: 0.8518\nEpoch 273/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3781 - accuracy: 0.8549\nEpoch 274/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3779 - accuracy: 0.8534\nEpoch 275/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3781 - accuracy: 0.8527\nEpoch 276/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3772 - accuracy: 0.8534\nEpoch 277/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3778 - accuracy: 0.8537\nEpoch 278/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3779 - accuracy: 0.8518\nEpoch 279/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3777 - accuracy: 0.8531\nEpoch 280/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3775 - accuracy: 0.8543\nEpoch 281/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3777 - accuracy: 0.8527\nEpoch 282/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3780 - accuracy: 0.8540\nEpoch 283/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3777 - accuracy: 0.8534\nEpoch 284/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3777 - accuracy: 0.8521\nEpoch 285/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3780 - accuracy: 0.8546\nEpoch 286/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3781 - accuracy: 0.8521\nEpoch 287/300\n3178/3178 [==============================] - 0s 51us/step - loss: 0.3777 - accuracy: 0.8531\nEpoch 288/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3782 - accuracy: 0.8537\nEpoch 289/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3776 - accuracy: 0.8527\nEpoch 290/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3779 - accuracy: 0.8543\nEpoch 291/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3773 - accuracy: 0.8524\nEpoch 292/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3773 - accuracy: 0.8534\nEpoch 293/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3774 - accuracy: 0.8531\nEpoch 294/300\n3178/3178 [==============================] - 0s 54us/step - loss: 0.3776 - accuracy: 0.8534\nEpoch 295/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3779 - accuracy: 0.8524\nEpoch 296/300\n3178/3178 [==============================] - 0s 53us/step - loss: 0.3776 - accuracy: 0.8540\nEpoch 297/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3776 - accuracy: 0.8524\nEpoch 298/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3776 - accuracy: 0.8543\nEpoch 299/300\n3178/3178 [==============================] - 0s 52us/step - loss: 0.3775 - accuracy: 0.8534\nEpoch 300/300\n3178/3178 [==============================] - 0s 55us/step - loss: 0.3778 - accuracy: 0.8531\n","name":"stdout"},{"output_type":"execute_result","execution_count":82,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7ff87ac234a8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"_,acc = model.evaluate(x_test,y_test)\nprint(\"Acc:{}\",acc*100)","execution_count":83,"outputs":[{"output_type":"stream","text":"1060/1060 [==============================] - 0s 98us/step\nAcc:{} 86.41509413719177\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}